{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import chardet\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing csvs\n",
    "materials_from_components = pd.read_csv('/Users/pablosoriano/Documents/Data Science/bbsr-challenge/all_uuid_materials_from_components.csv')\n",
    "obd_with_pollutants = pd.read_csv(\"pollutant_labeled_obd_translated.csv\", sep=\";\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates from obd_with_pollutants, keeping one for each module\n",
    "obd_with_pollutants_sorted = obd_with_pollutants.sort_values(by=[\"UUID\",\"Modul\"], ascending=[True, True])\n",
    "# removing duplicates from obd_with_pollutants, keeping one for each module\n",
    "obd_with_pollutants_clean = obd_with_pollutants_sorted.drop_duplicates(subset=[\"UUID\",\"Modul\"], keep=\"first\") # done in the previous step\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role keyword mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine relevant columns\n",
    "obd_with_pollutants[\"combined_text\"] = (\n",
    "    obd_with_pollutants[\"Name (de)\"].fillna(\"\") + \" \" +\n",
    "    obd_with_pollutants[\"Kategorie (original)\"].fillna(\"\") + \" \" +\n",
    "    obd_with_pollutants[\"productName\"].fillna(\"\") + \" \" +\n",
    "    obd_with_pollutants[\"eolCategoryName\"].fillna(\"\")\n",
    ").str.lower()\n",
    "\n",
    "# role mapping\n",
    "role_keywords = {\n",
    "    \"adhesive\": [\"kleber\", \"klebstoff\", \"spachtel\"],\n",
    "    \"sealant\": [\"abdichtung\", \"dicht\", \"fuge\", \"bitumen\", \"bitumenbahn\", \"epdm\", \"eva\", \"ecb\",\n",
    "                \"pvc\", \"dachbahn\", \"unterspannbahn\", \"kunststoffbahn\", \"dampfbremse\", \"folie\", \"vlies\"],\n",
    "    \"mortar\": [\"mörtel\", \"zement\", \"putz\", \"verputz\", \"fugenmörtel\", \"kalkzementputz\", \"leichtputz\", \"ausgleichsmasse\",\n",
    "               \"ziegel\", \"planstein\", \"leichtbeton\", \"dachstein\", \"glasbaustein\"],\n",
    "    \"coating\": [\"farbe\", \"beschichtung\", \"lack\", \"bodenbelag\", \"linoleum\", \"korklinoleum\", \"gussasphaltestrich\", \"pvc-bodenbelag\"],\n",
    "    \"insulation\": [\"dämm\", \"wolle\", \"schaum\", \"isolierung\"],\n",
    "    \"board\": [\"platte\", \"gipskarton\", \"holzfaser\"],\n",
    "    \"aggregate\": [\"kies\", \"schotter\", \"sand\", \"zuschlag\", \"granulat\", \"blähton\", \"naturbims\"],\n",
    "    \"metal\": [\"stahl\", \"metall\", \"blech\"],\n",
    "    \"wood\": [\"holz\", \"sperrholz\"]\n",
    "}\n",
    "def infer_role(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    for role, keywords in role_keywords.items():\n",
    "        if any(keyword in text for keyword in keywords):\n",
    "            return role\n",
    "    return None\n",
    "# Initial role inference\n",
    "obd_with_pollutants[\"material_role\"] = obd_with_pollutants[\"combined_text\"].apply(infer_role).fillna(\"other\")\n",
    "\n",
    "# Refine sealant into subroles\n",
    "def refine_sealant_role(row):\n",
    "    if row[\"material_role\"] != \"sealant\":\n",
    "        return row[\"material_role\"]\n",
    "    text = row[\"combined_text\"]\n",
    "    if any(x in text for x in [\"dachbahn\", \"epdm\", \"bitumen\", \"ecb\", \"eva\"]):\n",
    "        return \"roofing_sealant\"\n",
    "    elif any(x in text for x in [\"dampfbremse\", \"vlies\", \"folie\", \"unterspannbahn\"]):\n",
    "        return \"vapor_barrier\"\n",
    "    elif any(x in text for x in [\"pvc\", \"bodenbelag\", \"belag\"]):\n",
    "        return \"flooring_sealant\"\n",
    "    else:\n",
    "        return \"sealant\"\n",
    "    \n",
    " # Apply refinement\n",
    "obd_with_pollutants[\"material_role\"] = obd_with_pollutants.apply(refine_sealant_role, axis=1)\n",
    "\n",
    "# # Final role distribution\n",
    "# role_distribution = obd_with_pollutants[\"material_role\"].value_counts().sort_values(ascending=False)\n",
    "# role_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create multi-label one-hot encoded format for each unique row\n",
    "# We group by the full material context and pivot the target labels\n",
    "\n",
    "obd_with_pollutants[\"target_class\"] = obd_with_pollutants[\"Störstoffklasse\"]\n",
    "# Group by material context and pivot pollutant class into columns\n",
    "\n",
    "context_cols = [\"UUID\", \"material_role\", \"eolCategoryName\", \"eolScenarioUnbuiltReal\", \"eolScenarioUnbuiltPotential\", \"technologyFactor\"]\n",
    "df_multi = obd_with_pollutants[context_cols + [\"target_class\"]].dropna()#.drop_duplicates() #REVIEW - stay or go?\n",
    "df_multi[\"value\"] = 1\n",
    "df_pivot = df_multi.pivot_table(index=context_cols, columns=\"target_class\", values=\"value\", fill_value=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "label_cols = [col for col in df_pivot.columns if col.startswith(\"S\")]\n",
    "X = df_pivot.drop(columns=label_cols)\n",
    "y = df_pivot[label_cols]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_encoded = pd.get_dummies(X, columns=[\"material_role\", \"eolCategoryName\", \"eolScenarioUnbuiltReal\", \"eolScenarioUnbuiltPotential\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '91412f3f-6077-44d4-9c9d-95c543bcb419'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train multi-label Random Forest\u001b[39;00m\n\u001b[1;32m      5\u001b[0m multi_rf \u001b[38;5;241m=\u001b[39m MultiOutputClassifier(RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmulti_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Predict and evaluate\u001b[39;00m\n\u001b[1;32m      9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m multi_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/multioutput.py:542\u001b[0m, in \u001b[0;36mMultiOutputClassifier.fit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and targets Y.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m        Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [estimator\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_]\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/multioutput.py:274\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/multioutput.py:63\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     61\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/utils/validation.py:973\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 973\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '91412f3f-6077-44d4-9c9d-95c543bcb419'"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train multi-label Random Forest\n",
    "multi_rf = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = multi_rf.predict(X_test)\n",
    "report_multi = classification_report(y_test, y_pred, target_names=y.columns, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_proba = multi_rf.predict_proba(X_test)\n",
    "proba_df = pd.DataFrame({\n",
    "    class_name: probs[:, 1] for class_name, probs in zip(y.columns, y_proba)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      S0    S1     S2     S3     S4\n",
       "0  1.000  0.00  0.000  1.000  0.000\n",
       "1  1.000  0.00  0.000  1.000  0.000\n",
       "2  0.950  0.00  0.975  0.025  0.005\n",
       "3  0.815  0.26  0.720  0.950  0.075\n",
       "4  0.970  0.00  0.235  0.395  0.010"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom thresholds per class to convert probabilities into binary predictions\n",
    "custom_thresholds = {\n",
    "    \"S0\": 0.5,\n",
    "    \"S1\": 0.3,\n",
    "    \"S2\": 0.3,\n",
    "    \"S3\": 0.3,\n",
    "    \"S4\": 0.2\n",
    "}\n",
    "\n",
    "# Apply thresholds\n",
    "binary_predictions = pd.DataFrame({\n",
    "    class_name: (proba_df[class_name] >= threshold).astype(int)\n",
    "    for class_name, threshold in custom_thresholds.items()\n",
    "})\n",
    "\n",
    "# Evaluate the new thresholded predictions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "thresholded_report = classification_report(y_test, binary_predictions, target_names=y.columns, output_dict=True)\n",
    "# display as dataframe\n",
    "thresholded_report_df = pd.DataFrame(thresholded_report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.826263</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.831104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.863426</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.895089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.902857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score\n",
       "S0             0.944444  1.000000  0.971429\n",
       "S1             1.000000  1.000000  1.000000\n",
       "S2             0.909091  0.909091  0.909091\n",
       "S3             0.777778  1.000000  0.875000\n",
       "S4             0.500000  0.333333  0.400000\n",
       "micro avg      0.865385  0.937500  0.900000\n",
       "macro avg      0.826263  0.848485  0.831104\n",
       "weighted avg   0.863426  0.937500  0.895089\n",
       "samples avg    0.883333  0.941667  0.902857"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholded_report_df[['precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting pollutant clasess for unlabeld materials of Tbaustof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbs_df = pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/tbs_deduped.csv\", sep=\";\", quotechar='\"')\n",
    "\n",
    "# Continue with the feature processing pipeline\n",
    "tbs_df[\"combined_text\"] = (\n",
    "    tbs_df[\"productName\"].fillna(\"\") + \" \" +\n",
    "    tbs_df[\"eolCategoryName\"].fillna(\"\")\n",
    ").str.lower()\n",
    "\n",
    "# Infer role\n",
    "tbs_df[\"material_role\"] = tbs_df[\"combined_text\"].apply(infer_role).fillna(\"other\")\n",
    "tbs_df[\"material_role\"] = tbs_df.apply(refine_sealant_role, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create modeling features\n",
    "tbs_context = tbs_df[[\n",
    "    \"productName\",\"oekobaudatProcessUuid\", \"material_role\", \"eolCategoryName\",\n",
    "    \"eolScenarioUnbuiltReal\", \"eolScenarioUnbuiltPotential\", \"technologyFactor\"\n",
    "]].drop_duplicates()\n",
    "\n",
    "# One-hot encode and align with trained model\n",
    "tbs_encoded = pd.get_dummies(tbs_context.drop(columns=[\"productName\",\"oekobaudatProcessUuid\"]), drop_first=True)\n",
    "tbs_encoded = tbs_encoded.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Predict probabilities\n",
    "tbs_proba = multi_rf.predict_proba(tbs_encoded)\n",
    "tbs_proba_df = pd.DataFrame({\n",
    "    class_name: probs[:, 1] for class_name, probs in zip([\"S0\", \"S1\", \"S2\", \"S3\", \"S4\"], tbs_proba)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productName</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zinkbleche</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CR Profil (Chloropren-Kautschuk)</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Holz-Blendrahmen</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kunstharzputz</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dachziegel / Ton-</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Schaumglasgranulat SchÃ¼ttung</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>SchilfrohrdÃ¤mmmatte</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Schilfrohrmatte (PutztrÃ¤ger)</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Splitt 2/8, dauerelastisch gebunden (Latex, so...</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Wood-Plastic-Composites</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           productName     S0     S1     S2  \\\n",
       "0                                           Zinkbleche  0.880  0.000  0.950   \n",
       "1                     CR Profil (Chloropren-Kautschuk)  0.605  0.050  0.285   \n",
       "2                                     Holz-Blendrahmen  0.945  0.460  0.625   \n",
       "3                                        Kunstharzputz  0.985  0.055  0.095   \n",
       "4                                    Dachziegel / Ton-  0.920  0.000  0.335   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "333                      Schaumglasgranulat SchÃ¼ttung  0.900  0.115  0.565   \n",
       "334                               SchilfrohrdÃ¤mmmatte  0.860  0.145  0.390   \n",
       "335                      Schilfrohrmatte (PutztrÃ¤ger)  0.905  0.105  0.435   \n",
       "336  Splitt 2/8, dauerelastisch gebunden (Latex, so...  0.975  0.140  0.180   \n",
       "337                            Wood-Plastic-Composites  0.605  0.050  0.285   \n",
       "\n",
       "        S3     S4  \n",
       "0    0.025  0.005  \n",
       "1    0.305  0.335  \n",
       "2    0.260  0.490  \n",
       "3    0.305  0.015  \n",
       "4    0.275  0.105  \n",
       "..     ...    ...  \n",
       "333  0.370  0.010  \n",
       "334  0.615  0.035  \n",
       "335  0.695  0.060  \n",
       "336  0.605  0.015  \n",
       "337  0.305  0.335  \n",
       "\n",
       "[338 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply thresholds\n",
    "tbs_predicted = pd.DataFrame({\n",
    "    class_name: (tbs_proba_df[class_name] >= threshold).astype(int)\n",
    "    for class_name, threshold in custom_thresholds.items()\n",
    "})\n",
    "\n",
    "# Combine with UUIDs\n",
    "tbs_results = pd.concat([tbs_context.reset_index(drop=True)[[\"productName\"]], tbs_predicted], axis=1)\n",
    "\n",
    "tbs_results\n",
    "## Pollutant Class Probabilities For TBaustoff\n",
    "tbs_proba_df[\"productName\"] = tbs_context[\"productName\"].values\n",
    "tbs_proba_df[\"UUID\"] = tbs_context[\"oekobaudatProcessUuid\"].values\n",
    "\n",
    "# Reorder columns for clarity\n",
    "columns_ordered = [\"productName\",\"S0\", \"S1\", \"S2\", \"S3\", \"S4\"]\n",
    "tbs_proba_df = tbs_proba_df[columns_ordered]\n",
    "\n",
    "# to csv\n",
    "tbs_proba_df.to_csv(\"tbs_proba_df.csv\", index=False)\n",
    "tbs_proba_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Contaminant Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and rank the most common contaminant terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kj/_mqw0wd165b_qz356cmtmkzc0000gn/T/ipykernel_3881/3486000062.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"contaminant_tokens\"] = df_valid[\"Fremd-/Störstoffbeschreibung\"].apply(tokenize_contaminants)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('klebereste', 209),\n",
       " ('putze', 107),\n",
       " ('klebespachtel', 100),\n",
       " ('mit', 96),\n",
       " ('gipskarton', 85),\n",
       " ('verunreinigt', 65),\n",
       " ('kaschierung', 64),\n",
       " ('belagsreste', 57),\n",
       " ('klebstoff', 48),\n",
       " ('metallteile', 43),\n",
       " ('bitumenreste', 37),\n",
       " ('dämmstoff', 33),\n",
       " ('kunststoff/bitumen', 33),\n",
       " ('bahnen', 33),\n",
       " ('beschichtungen', 33),\n",
       " ('bitumenbahnen', 32),\n",
       " ('dampfdruckausgleichsschicht', 30),\n",
       " ('metalleinlage', 30),\n",
       " ('gipsspachtel', 29),\n",
       " ('wandfarbe', 29),\n",
       " ('geringf', 29),\n",
       " ('verunr', 29),\n",
       " ('kunststoffen', 29),\n",
       " ('dämmstoffen', 29),\n",
       " ('metallkasch', 29),\n",
       " ('massivbaustoffen', 29),\n",
       " ('klebstoffreste', 29),\n",
       " ('beschichtung', 29),\n",
       " ('geringfügig', 28),\n",
       " ('konv', 28)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Filter for meaningful descriptions\n",
    "df_valid = obd_with_pollutants[\n",
    "    obd_with_pollutants[\"Fremd-/Störstoffbeschreibung\"].notna() &\n",
    "    (obd_with_pollutants[\"Fremd-/Störstoffbeschreibung\"].str.lower() != \"ohne fremd-/störstoffe\")\n",
    "]\n",
    "\n",
    "# Tokenize contaminant terms\n",
    "def tokenize_contaminants(desc):\n",
    "    return re.findall(r'[\\w/]+', desc.lower())\n",
    "\n",
    "df_valid[\"contaminant_tokens\"] = df_valid[\"Fremd-/Störstoffbeschreibung\"].apply(tokenize_contaminants)\n",
    "\n",
    "# Flatten and count all tokens\n",
    "all_tokens = [token for sublist in df_valid[\"contaminant_tokens\"] for token in sublist]\n",
    "contaminant_counts = Counter(all_tokens)\n",
    "\n",
    "# Show the 30 most frequent contaminant terms\n",
    "contaminant_counts.most_common(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                 label_klebereste       1.00      1.00      1.00        44\n",
      "                      label_putze       0.92      1.00      0.96        23\n",
      "              label_klebespachtel       0.88      0.96      0.92        23\n",
      "                        label_mit       1.00      0.63      0.77        19\n",
      "                 label_gipskarton       1.00      1.00      1.00        19\n",
      "               label_verunreinigt       0.00      0.00      0.00        13\n",
      "                label_kaschierung       1.00      1.00      1.00        13\n",
      "                label_belagsreste       0.00      0.00      0.00        12\n",
      "                  label_klebstoff       0.40      0.18      0.25        11\n",
      "                label_metallteile       1.00      0.20      0.33         5\n",
      "               label_bitumenreste       0.00      0.00      0.00         5\n",
      "                  label_dämmstoff       0.00      0.00      0.00         8\n",
      "         label_kunststoff/bitumen       0.00      0.00      0.00         8\n",
      "                     label_bahnen       0.00      0.00      0.00         8\n",
      "             label_beschichtungen       0.00      0.00      0.00         8\n",
      "              label_bitumenbahnen       0.33      1.00      0.50         4\n",
      "label_dampfdruckausgleichsschicht       0.33      1.00      0.50         4\n",
      "              label_metalleinlage       0.33      1.00      0.50         4\n",
      "               label_gipsspachtel       0.00      0.00      0.00         4\n",
      "                  label_wandfarbe       0.00      0.00      0.00         7\n",
      "                    label_geringf       0.00      0.00      0.00         7\n",
      "                     label_verunr       0.00      0.00      0.00         7\n",
      "               label_kunststoffen       0.00      0.00      0.00         7\n",
      "                label_dämmstoffen       0.00      0.00      0.00         7\n",
      "                label_metallkasch       0.00      0.00      0.00         7\n",
      "           label_massivbaustoffen       0.00      0.00      0.00         7\n",
      "             label_klebstoffreste       0.00      0.00      0.00         5\n",
      "               label_beschichtung       0.00      0.00      0.00         6\n",
      "                label_geringfügig       0.00      0.00      0.00         5\n",
      "                       label_konv       0.00      0.00      0.00         5\n",
      "\n",
      "                        micro avg       0.81      0.49      0.61       305\n",
      "                        macro avg       0.27      0.30      0.26       305\n",
      "                     weighted avg       0.49      0.49      0.47       305\n",
      "                      samples avg       0.60      0.59      0.60       305\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/codeacademy/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# -----------------------\n",
    "# LOAD AND CLEAN DATA\n",
    "# -----------------------\n",
    "obd_with_pollutants = pd.read_csv(\"pollutant_labeled_obd_translated.csv\", sep=\";\", quotechar='\"')\n",
    "\n",
    "# Filter valid pollutant description rows\n",
    "df_valid = obd_with_pollutants[\n",
    "    obd_with_pollutants[\"Fremd-/Störstoffbeschreibung\"].notna() &\n",
    "    (obd_with_pollutants[\"Fremd-/Störstoffbeschreibung\"].str.lower() != \"ohne fremd-/störstoffe\")\n",
    "].copy()\n",
    "\n",
    "# -----------------------\n",
    "# TOKENIZE CONTAMINANTS\n",
    "# -----------------------\n",
    "def tokenize_contaminants(desc):\n",
    "    return re.findall(r'[\\w/]+', desc.lower())\n",
    "\n",
    "df_valid[\"contaminant_tokens\"] = df_valid[\"Fremd-/Störstoffbeschreibung\"].apply(tokenize_contaminants)\n",
    "\n",
    "# Count most frequent tokens\n",
    "all_tokens = [t for tokens in df_valid[\"contaminant_tokens\"] for t in tokens]\n",
    "top_terms = [term for term, _ in Counter(all_tokens).most_common(30)]\n",
    "\n",
    "# Create binary label columns\n",
    "for term in top_terms:\n",
    "    df_valid[f\"label_{term}\"] = df_valid[\"contaminant_tokens\"].apply(lambda tokens: int(term in tokens))\n",
    "\n",
    "label_columns = [f\"label_{term}\" for term in top_terms]\n",
    "\n",
    "# -----------------------\n",
    "# MATERIAL ROLE MAPPING\n",
    "# -----------------------\n",
    "role_keywords = {\n",
    "    \"adhesive\": [\"kleber\", \"klebstoff\", \"spachtel\"],\n",
    "    \"sealant\": [\"abdichtung\", \"dicht\", \"fuge\", \"bitumen\", \"bitumenbahn\", \"epdm\", \"eva\", \"ecb\",\n",
    "                \"pvc\", \"dachbahn\", \"unterspannbahn\", \"kunststoffbahn\", \"dampfbremse\", \"folie\", \"vlies\"],\n",
    "    \"mortar\": [\"mörtel\", \"zement\", \"putz\", \"verputz\", \"fugenmörtel\", \"kalkzementputz\", \"leichtputz\", \"ausgleichsmasse\",\n",
    "               \"ziegel\", \"planstein\", \"leichtbeton\", \"dachstein\", \"glasbaustein\"],\n",
    "    \"coating\": [\"farbe\", \"beschichtung\", \"lack\", \"bodenbelag\", \"linoleum\", \"korklinoleum\", \"gussasphaltestrich\", \"pvc-bodenbelag\"],\n",
    "    \"insulation\": [\"dämm\", \"wolle\", \"schaum\", \"isolierung\"],\n",
    "    \"board\": [\"platte\", \"gipskarton\", \"holzfaser\"],\n",
    "    \"aggregate\": [\"kies\", \"schotter\", \"sand\", \"zuschlag\", \"granulat\", \"blähton\", \"naturbims\"],\n",
    "    \"metal\": [\"stahl\", \"metall\", \"blech\"],\n",
    "    \"wood\": [\"holz\", \"sperrholz\"]\n",
    "}\n",
    "\n",
    "def infer_role(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    for role, keywords in role_keywords.items():\n",
    "        if any(keyword in text for keyword in keywords):\n",
    "            return role\n",
    "    return \"other\"\n",
    "\n",
    "def refine_sealant_role(row):\n",
    "    if row[\"material_role\"] != \"sealant\":\n",
    "        return row[\"material_role\"]\n",
    "    text = row[\"combined_text\"]\n",
    "    if any(x in text for x in [\"dachbahn\", \"epdm\", \"bitumen\", \"ecb\", \"eva\"]):\n",
    "        return \"roofing_sealant\"\n",
    "    elif any(x in text for x in [\"dampfbremse\", \"vlies\", \"folie\", \"unterspannbahn\"]):\n",
    "        return \"vapor_barrier\"\n",
    "    elif any(x in text for x in [\"pvc\", \"bodenbelag\", \"belag\"]):\n",
    "        return \"flooring_sealant\"\n",
    "    else:\n",
    "        return \"sealant\"\n",
    "\n",
    "# Apply role inference\n",
    "df_valid[\"combined_text\"] = (\n",
    "    df_valid[\"Name (de)\"].fillna(\"\") + \" \" +\n",
    "    df_valid[\"Kategorie (original)\"].fillna(\"\") + \" \" +\n",
    "    df_valid[\"productName\"].fillna(\"\") + \" \" +\n",
    "    df_valid[\"eolCategoryName\"].fillna(\"\")\n",
    ").str.lower()\n",
    "\n",
    "df_valid[\"material_role\"] = df_valid[\"combined_text\"].apply(infer_role).fillna(\"other\")\n",
    "df_valid[\"material_role\"] = df_valid.apply(refine_sealant_role, axis=1)\n",
    "\n",
    "# -----------------------\n",
    "# PREPARE FEATURES\n",
    "# -----------------------\n",
    "# Use core context + pollutant class as input\n",
    "df_model = df_valid[[\n",
    "    \"material_role\", \"eolCategoryName\", \"eolScenarioUnbuiltReal\",\n",
    "    \"eolScenarioUnbuiltPotential\", \"technologyFactor\"\n",
    "]]\n",
    "\n",
    "\n",
    "# One-hot encode all features\n",
    "X = pd.get_dummies(df_model, drop_first=True)\n",
    "y = df_valid[label_columns]\n",
    "\n",
    "# -----------------------\n",
    "# TRAINING\n",
    "# -----------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------\n",
    "# EVALUATION\n",
    "# -----------------------\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, target_names=y.columns)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked contaminant prediction pipeline\n",
    "# 1. Train pollutant class model (S0-S4)\n",
    "# 2. Predict class probabilities\n",
    "# 3. Train contaminant model using those probabilities\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ------------------\n",
    "# LOAD & CLEAN DATA\n",
    "# ------------------\n",
    "obd_with_pollutants = pd.read_csv(\"pollutant_labeled_obd_translated.csv\", sep=\";\", quotechar='\"')\n",
    "obd_with_pollutants = obd_with_pollutants.dropna(subset=[\"Fremd-/Störstoffbeschreibung\"])  # drop missing labels\n",
    "\n",
    "# --------------------------\n",
    "# TOKENIZATION + LABEL CLEANING\n",
    "# --------------------------\n",
    "\n",
    "def tokenize(desc):\n",
    "    return re.findall(r\"[\\w/]+\", desc.lower())\n",
    "\n",
    "def apply_label_cleaning(tokens):\n",
    "    replacements = {\n",
    "        # unify all glue-related terms under \"klebstoff\"\n",
    "        \"kleber\": \"klebstoff\",\n",
    "        \"kleberreste\": \"klebstoff\",\n",
    "        \"klebstoffreste\": \"klebstoff\",\n",
    "        \"klebstoffe\": \"klebstoff\",\n",
    "        \"klebereste\": \"klebstoff\",\n",
    "\n",
    "        # unify bitumen variants\n",
    "        \"bitumenreste\": \"bitumen\",\n",
    "        \"bitumenbahnen\": \"bitumen\",\n",
    "        \"bitumendickschicht\": \"bitumen\",\n",
    "        \"kunststoff/bitumen\": \"bitumen\",\n",
    "\n",
    "        # coatings\n",
    "        \"beschichtungen\": \"beschichtung\",\n",
    "        \"reaktionsharzbeschichtung\": \"beschichtung\",\n",
    "        \"beschichtet\": \"beschichtung\",\n",
    "\n",
    "        # insulation\n",
    "        \"dämmstoffe\": \"dämmstoff\",\n",
    "        \"dämmstoffreste\": \"dämmstoff\",\n",
    "        \"dämmstoffen\": \"dämmstoff\",\n",
    "\n",
    "        # gypsum and plaster\n",
    "        \"gipsspachtel\": \"gips\",\n",
    "        \"gipskarton\": \"gips\",\n",
    "        \"gipsputz\": \"gips\",\n",
    "        \"putze\": \"putz\",\n",
    "\n",
    "        # mortar\n",
    "        \"kalkmörtel\": \"mörtel\",\n",
    "        \"kalkzementmörtel\": \"mörtel\",\n",
    "\n",
    "        # sealing\n",
    "        \"feuchteabdichtung\": \"abdichtung\",\n",
    "        \"flüssigabdichtungen\": \"abdichtung\",\n",
    "        \"abdichtungen\": \"abdichtung\",\n",
    "\n",
    "        # other\n",
    "        \"kunststoffen\": \"kunststoff\",\n",
    "        \"bodenbelagsreste\": \"belagsreste\",\n",
    "        \"klebespachtel\": \"klebstoff\",\n",
    "        \"massivbaustoffen\": \"massivbaustoff\",\n",
    "        \"stahlbewehrung\": \"bewehrung\",\n",
    "        \"bewehrungsstahl\": \"bewehrung\",\n",
    "        \"naturfarbe\": \"farbe\"\n",
    "    }\n",
    "    return [replacements.get(t, t) for t in tokens]\n",
    "\n",
    "# Apply tokenization and cleaning\n",
    "obd_with_pollutants[\"tokens\"] = obd_with_pollutants[\"Fremd-/Störstoffbeschreibung\"]\\\n",
    "    .apply(tokenize).apply(apply_label_cleaning)\n",
    "\n",
    "# --------------------------\n",
    "# TERM SELECTION AND LABEL CREATION\n",
    "# --------------------------\n",
    "\n",
    "# Exclude stopwords and noise\n",
    "skip = {\n",
    "    \"ohne\", \"mit\", \"verunr\", \"geringf\", \"fremd\", \"/störstoffe\", \"verunreinigt\",\n",
    "    \"geringfügig\", \"konv\", \"in\", \"z\", \"b\", \"wdvs\", \"geringen\", \"mengen\"\n",
    "}\n",
    "\n",
    "# Get cleaned tokens\n",
    "all_tokens = [t for tokens in obd_with_pollutants[\"tokens\"] for t in tokens if t not in skip]\n",
    "\n",
    "# Choose top 15 (cleaned and consolidated)\n",
    "top_terms = [term for term, _ in Counter(all_tokens).most_common(15)]\n",
    "\n",
    "# Create binary labels for each of the top terms\n",
    "for term in top_terms:\n",
    "    obd_with_pollutants[f\"label_{term}\"] = obd_with_pollutants[\"tokens\"].apply(lambda tokens: int(term in tokens))\n",
    "\n",
    "# Final contaminant labels to use in y\n",
    "contaminant_labels = [f\"label_{term}\" for term in top_terms]\n",
    "\n",
    "# ----------------------\n",
    "# ROLE INFERENCE + TEXT\n",
    "# ----------------------\n",
    "role_keywords = {\n",
    "    \"adhesive\": [\"kleber\", \"klebstoff\", \"spachtel\"],\n",
    "    \"sealant\": [\"abdichtung\", \"dicht\", \"fuge\", \"bitumen\", \"bitumenbahn\", \"epdm\", \"eva\", \"ecb\",\n",
    "                 \"pvc\", \"dachbahn\", \"unterspannbahn\", \"kunststoffbahn\", \"dampfbremse\", \"folie\", \"vlies\"],\n",
    "    \"mortar\": [\"mörtel\", \"zement\", \"putz\", \"verputz\", \"fugenmörtel\", \"kalkzementputz\", \"leichtputz\", \"ausgleichsmasse\",\n",
    "               \"ziegel\", \"planstein\", \"leichtbeton\", \"dachstein\", \"glasbaustein\"],\n",
    "    \"coating\": [\"farbe\", \"beschichtung\", \"lack\", \"bodenbelag\", \"linoleum\", \"korklinoleum\", \"gussasphaltestrich\", \"pvc-bodenbelag\"],\n",
    "    \"insulation\": [\"dämm\", \"wolle\", \"schaum\", \"isolierung\"],\n",
    "    \"board\": [\"platte\", \"gipskarton\", \"holzfaser\"],\n",
    "    \"aggregate\": [\"kies\", \"schotter\", \"sand\", \"zuschlag\", \"granulat\", \"blähton\", \"naturbims\"],\n",
    "    \"metal\": [\"stahl\", \"metall\", \"blech\"],\n",
    "    \"wood\": [\"holz\", \"sperrholz\"]\n",
    "}\n",
    "\n",
    "def infer_role(text):\n",
    "    for role, keywords in role_keywords.items():\n",
    "        if any(k in text for k in keywords):\n",
    "            return role\n",
    "    return \"other\"\n",
    "\n",
    "def refine_sealant(row):\n",
    "    if row[\"material_role\"] != \"sealant\": return row[\"material_role\"]\n",
    "    t = row[\"combined_text\"]\n",
    "    if any(x in t for x in [\"dachbahn\", \"epdm\", \"bitumen\", \"ecb\", \"eva\"]): return \"roofing_sealant\"\n",
    "    if any(x in t for x in [\"dampfbremse\", \"vlies\", \"folie\", \"unterspannbahn\"]): return \"vapor_barrier\"\n",
    "    if any(x in t for x in [\"pvc\", \"bodenbelag\", \"belag\"]): return \"flooring_sealant\"\n",
    "    return \"sealant\"\n",
    "\n",
    "# Combine fields\n",
    "text = (obd_with_pollutants[\"Name (de)\"].fillna(\"\") + \" \" + obd_with_pollutants[\"Kategorie (original)\"].fillna(\"\") +\n",
    "        \" \" + obd_with_pollutants[\"productName\"].fillna(\"\") + \" \" + obd_with_pollutants[\"eolCategoryName\"].fillna(\"\")).str.lower()\n",
    "obd_with_pollutants[\"combined_text\"] = text\n",
    "obd_with_pollutants[\"material_role\"] = obd_with_pollutants[\"combined_text\"].apply(infer_role)\n",
    "obd_with_pollutants[\"material_role\"] = obd_with_pollutants.apply(refine_sealant, axis=1)\n",
    "\n",
    "# --------------------------\n",
    "# STAGE 1: POLLUTANT CLASS\n",
    "# # --------------------------\n",
    "\n",
    "df_class = pd.get_dummies(obd_with_pollutants[\"Störstoffklasse\"])\n",
    "\n",
    "X_context = obd_with_pollutants[[\"material_role\", \"eolCategoryName\", \"eolScenarioUnbuiltReal\", \"eolScenarioUnbuiltPotential\", \"technologyFactor\"]]\n",
    "X_class = pd.get_dummies(X_context, drop_first=True)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_class, df_class, test_size=0.2, random_state=42)\n",
    "model_class = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "model_class.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict class probs (for stage 2 input)\n",
    "class_probs = model_class.predict_proba(X_class)\n",
    "class_probs_df = pd.DataFrame({label: prob[:, 1] for label, prob in zip(df_class.columns, class_probs)}, index=obd_with_pollutants.index)\n",
    "\n",
    "# TF-IDF on productName\n",
    "tfidf = TfidfVectorizer(max_features=100, stop_words=None)\n",
    "X_text = tfidf.fit_transform(obd_with_pollutants[\"productName\"].fillna(\"\").astype(str))\n",
    "X_text_df = pd.DataFrame(X_text.toarray(), index=obd_with_pollutants.index, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Combine all features\n",
    "X_combined_tfidf = pd.concat([X_context.reset_index(drop=True), class_probs_df.reset_index(drop=True), X_text_df.reset_index(drop=True)], axis=1)\n",
    "X_final_tfidf = pd.get_dummies(X_combined_tfidf, drop_first=True)\n",
    "y_final_tfidf = obd_with_pollutants[contaminant_labels]\n",
    "\n",
    "# --------------------------\n",
    "# STAGE 2: CONTAMINANT MODEL\n",
    "# --------------------------\n",
    "# Train contaminant model with TF-IDF-enhanced features\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_final_tfidf, y_final_tfidf, test_size=0.2, random_state=42)\n",
    "model_tfidf = MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "model_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "report_tfidf = classification_report(y_test_tfidf, y_pred_tfidf, target_names=y_final_tfidf.columns, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as dataframe\n",
    "report_tfidf_df = pd.DataFrame(report_tfidf).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label_klebstoff</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_gips</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_putz</th>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.406780</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_bitumen</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_dämmstoff</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_beschichtung</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_belagsreste</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_kaschierung</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_metallteile</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_bahnen</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_kunststoff</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_mörtel</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_dampfdruckausgleichsschicht</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_metalleinlage</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_wandfarbe</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.360515</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.310684</td>\n",
       "      <td>0.269744</td>\n",
       "      <td>0.275121</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.340978</td>\n",
       "      <td>0.306569</td>\n",
       "      <td>0.317129</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.184969</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>0.182688</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   precision    recall  f1-score  support\n",
       "label_klebstoff                     0.333333  0.282051  0.305556     78.0\n",
       "label_gips                          0.320000  0.275862  0.296296     29.0\n",
       "label_putz                          0.387097  0.428571  0.406780     28.0\n",
       "label_bitumen                       0.640000  0.615385  0.627451     26.0\n",
       "label_dämmstoff                     0.294118  0.263158  0.277778     19.0\n",
       "label_beschichtung                  0.266667  0.235294  0.250000     17.0\n",
       "label_belagsreste                   0.000000  0.000000  0.000000     15.0\n",
       "label_kaschierung                   0.333333  0.312500  0.322581     16.0\n",
       "label_metallteile                   1.000000  0.285714  0.444444      7.0\n",
       "label_bahnen                        0.300000  0.300000  0.300000     10.0\n",
       "label_kunststoff                    0.000000  0.000000  0.000000      6.0\n",
       "label_mörtel                        0.500000  0.714286  0.588235      7.0\n",
       "label_dampfdruckausgleichsschicht   0.142857  0.166667  0.153846      6.0\n",
       "label_metalleinlage                 0.142857  0.166667  0.153846      6.0\n",
       "label_wandfarbe                     0.000000  0.000000  0.000000      4.0\n",
       "micro avg                           0.360515  0.306569  0.331361    274.0\n",
       "macro avg                           0.310684  0.269744  0.275121    274.0\n",
       "weighted avg                        0.340978  0.306569  0.317129    274.0\n",
       "samples avg                         0.184969  0.181854  0.182688    274.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_klebstoff</th>\n",
       "      <th>label_gips</th>\n",
       "      <th>label_putz</th>\n",
       "      <th>label_bitumen</th>\n",
       "      <th>label_dämmstoff</th>\n",
       "      <th>label_beschichtung</th>\n",
       "      <th>label_belagsreste</th>\n",
       "      <th>label_kaschierung</th>\n",
       "      <th>label_metallteile</th>\n",
       "      <th>label_bahnen</th>\n",
       "      <th>label_kunststoff</th>\n",
       "      <th>label_mörtel</th>\n",
       "      <th>label_dampfdruckausgleichsschicht</th>\n",
       "      <th>label_metalleinlage</th>\n",
       "      <th>label_wandfarbe</th>\n",
       "      <th>top_contaminants</th>\n",
       "      <th>productName</th>\n",
       "      <th>UUID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.212224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>PE/PP Vlies</td>\n",
       "      <td>91412f3f-6077-44d4-9c9d-95c543bcb419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.276623</td>\n",
       "      <td>0.145617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102801</td>\n",
       "      <td>0.143951</td>\n",
       "      <td>0.166978</td>\n",
       "      <td>0.276623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143951</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173822</td>\n",
       "      <td>klebstoff (0.28), belagsreste (0.28)</td>\n",
       "      <td>Gipskartonplatte (imprÃ¤gniert)</td>\n",
       "      <td>deeb0bda-20fa-412a-b945-1a589638db21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.569138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>klebstoff (0.57)</td>\n",
       "      <td>Unterspannbahn PUR auf PET-Vlies</td>\n",
       "      <td>ed734c48-a58f-4f92-a9f7-57631b500fdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.499378</td>\n",
       "      <td>0.231423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.267905</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491408</td>\n",
       "      <td>klebstoff (0.50), belagsreste (0.50), wandfarb...</td>\n",
       "      <td>Gipsfaserplatte</td>\n",
       "      <td>1b0a3488-9b02-4c98-b421-8c746d350f97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.447765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>klebstoff (0.45)</td>\n",
       "      <td>PE/PP Vlies</td>\n",
       "      <td>6869f7c1-1b2b-4f30-afc9-823a0104f1d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_klebstoff  label_gips  label_putz  label_bitumen  label_dämmstoff  \\\n",
       "708         0.212224    0.000000         0.0       0.000000         0.000000   \n",
       "215         0.276623    0.145617         0.0       0.102801         0.143951   \n",
       "882         0.569138    0.000000         0.0       0.000000         0.000000   \n",
       "88          0.499378    0.231423         0.0       0.000000         0.269155   \n",
       "842         0.447765    0.000000         0.0       0.000000         0.000000   \n",
       "\n",
       "     label_beschichtung  label_belagsreste  label_kaschierung  \\\n",
       "708            0.000000           0.000000                0.0   \n",
       "215            0.166978           0.276623                0.0   \n",
       "882            0.000000           0.000000                0.0   \n",
       "88             0.000000           0.497756                0.0   \n",
       "842            0.000000           0.000000                0.0   \n",
       "\n",
       "     label_metallteile  label_bahnen  label_kunststoff  label_mörtel  \\\n",
       "708           0.000000           0.0          0.000000       0.00000   \n",
       "215           0.100612           0.0          0.143951       0.00000   \n",
       "882           0.000000           0.0          0.000000       0.00000   \n",
       "88            0.000000           0.0          0.267905       0.00125   \n",
       "842           0.000000           0.0          0.000000       0.00000   \n",
       "\n",
       "     label_dampfdruckausgleichsschicht  label_metalleinlage  label_wandfarbe  \\\n",
       "708                                0.0                  0.0         0.000000   \n",
       "215                                0.0                  0.0         0.173822   \n",
       "882                                0.0                  0.0         0.000000   \n",
       "88                                 0.0                  0.0         0.491408   \n",
       "842                                0.0                  0.0         0.000000   \n",
       "\n",
       "                                      top_contaminants  \\\n",
       "708                                                      \n",
       "215               klebstoff (0.28), belagsreste (0.28)   \n",
       "882                                   klebstoff (0.57)   \n",
       "88   klebstoff (0.50), belagsreste (0.50), wandfarb...   \n",
       "842                                   klebstoff (0.45)   \n",
       "\n",
       "                          productName                                  UUID  \n",
       "708                       PE/PP Vlies  91412f3f-6077-44d4-9c9d-95c543bcb419  \n",
       "215   Gipskartonplatte (imprÃ¤gniert)  deeb0bda-20fa-412a-b945-1a589638db21  \n",
       "882  Unterspannbahn PUR auf PET-Vlies  ed734c48-a58f-4f92-a9f7-57631b500fdc  \n",
       "88                    Gipsfaserplatte  1b0a3488-9b02-4c98-b421-8c746d350f97  \n",
       "842                       PE/PP Vlies  6869f7c1-1b2b-4f30-afc9-823a0104f1d9  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# THRESHOLDED PROBABILITIES\n",
    "# --------------------------\n",
    "\n",
    "# Predict raw probabilities\n",
    "y_proba = model_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "proba_df = pd.DataFrame({\n",
    "    label: probs[:, 1] for label, probs in zip(y_final_tfidf.columns, y_proba)\n",
    "}, index=X_test_tfidf.index)\n",
    "\n",
    "# Threshold at 0.3 → likely present\n",
    "likely_present = proba_df >= 0.3\n",
    "\n",
    "# Threshold at 0.5 → very likely present\n",
    "very_likely = proba_df >= 0.5\n",
    "\n",
    "# Optional: show top N contaminants per row with scores\n",
    "def rank_top_contaminants(row, threshold=0.25, top_n=3):\n",
    "    sorted_labels = row[row >= threshold].sort_values(ascending=False)\n",
    "    return \", \".join([f\"{lbl.replace('label_', '')} ({prob:.2f})\" for lbl, prob in sorted_labels.items()][:top_n])\n",
    "\n",
    "proba_df[\"top_contaminants\"] = proba_df.apply(rank_top_contaminants, axis=1)\n",
    "\n",
    "# Attach productName and UUID from original dataset\n",
    "proba_df[\"productName\"] = obd_with_pollutants.loc[X_test_tfidf.index, \"productName\"].values\n",
    "proba_df[\"UUID\"] = obd_with_pollutants.loc[X_test_tfidf.index, \"UUID\"].values\n",
    "\n",
    "# Example output:\n",
    "proba_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Pollutants Based on Material Combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obd_with_pollutants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Keep only relevant columns\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m obd_with_pollutants \u001b[38;5;241m=\u001b[39m \u001b[43mobd_with_pollutants\u001b[49m[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUUID\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStörstoffklasse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFremd-/Störstoffbeschreibung\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUUID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Merge pollutant data into the component summary by exploding material_uuids\u001b[39;00m\n\u001b[1;32m      5\u001b[0m exploded \u001b[38;5;241m=\u001b[39m grouped[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_component_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaterial_uuids\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaterial_uuids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaterial_uuids\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muuid\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obd_with_pollutants' is not defined"
     ]
    }
   ],
   "source": [
    "# Keep only relevant columns\n",
    "obd_with_pollutants = obd_with_pollutants[[\"UUID\", \"Störstoffklasse\", \"Fremd-/Störstoffbeschreibung\"]].rename(columns={\"UUID\": \"uuid\"})\n",
    "\n",
    "# Merge pollutant data into the component summary by exploding material_uuids\n",
    "exploded = grouped[[\"main_component_id\", \"material_uuids\"]].explode(\"material_uuids\").rename(columns={\"material_uuids\": \"uuid\"})\n",
    "\n",
    "# Join pollutant labels per material UUID\n",
    "component_pollutants = exploded.merge(obd_with_pollutants, on=\"uuid\", how=\"left\")\n",
    "\n",
    "# Re-aggregate by component\n",
    "agg_pollutants = component_pollutants.groupby(\"main_component_id\").agg({\n",
    "    \"Störstoffklasse\": lambda x: list(x.dropna().unique()),\n",
    "    \"Fremd-/Störstoffbeschreibung\": lambda x: list(x.dropna().unique())\n",
    "}).reset_index()\n",
    "\n",
    "# Join back into original component summary\n",
    "component_labeled = grouped.merge(agg_pollutants, on=\"main_component_id\", how=\"left\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeacademy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# ğŸ§ª Pollutant Prediction in Construction Materials

This project builds a machine learning system to predict **pollutant classifications** in building materials based on Ã–KOBAUDAT data, material roles, and end-of-life scenarios. It supports more efficient sustainability assessments and helps automate pollutant detection for circular construction tools.

---

## ğŸ§© Problem Statement

Current sustainability assessments rely on manual inputs to determine which pollutants (e.g., adhesives, coatings, fire retardants) are present in construction materials. This process is:
- Time-consuming
- Error-prone
- Not scalable

Our solution: A trained model that **automatically predicts pollutant presence** based on a materialâ€™s characteristics and context.

---

## ğŸ” Objectives

- Predict `StÃ¶rstoffklasse` (pollutant classes: S0â€“S4)
- Suggest likely **contaminant terms** using text mining
- Blend predictions with **component-level** context from `bauteileditor.de`
- Provide strong default values to reduce manual input

---

## ğŸ§± Dataset

- `pollutant_labeled_obd.csv`: bootstrapped multi-label pollutant annotations
- `tBaustoff_with_OBD_mapping.csv`: technical building materials
- `all_uuid_materials_from_components.csv`: links materials to components
- Manual + scraped data from [bauteileditor.de](https://bauteileditor.de)

---

## ğŸ§  Model Pipeline

### 1. `build_features.py`
- Loads datasets
- Infers material role from text (e.g. adhesive, sealant, mortar)
- One-hot encodes EOL scenarios and other categorical features

### 2. `train_pollutant_model.py`
- Trains a `MultiOutputClassifier` using Random Forest
- Saves model + predictions + probability scores

### 3. `inference_pipeline.py`
- Makes predictions on unlabeled materials
- Applies class-specific thresholds
- Blends material-level and component-level probabilities

### 4. `visualize_results.py`
- Generates performance barplots and label distributions
- Saves top predicted pollutant classes for inspection

---

## ğŸ“ Project Structure

```
bbsr-challenge/
â”‚
â”œâ”€â”€ data/                    # Raw and processed datasets
â”œâ”€â”€ results/
â”‚   â””â”€â”€ figures/             # Plots, metrics, top predictions
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pollutant_predictor/
â”‚       â”œâ”€â”€ data/           # Dataset loading utilities
â”‚       â”œâ”€â”€ features/       # Role inference + preprocessing
â”‚       â”œâ”€â”€ models/         # Training + evaluation functions
â”‚       â””â”€â”€ inference/      # Prediction and blending pipeline
â”œâ”€â”€ scripts/                # Executable scripts
â”‚   â”œâ”€â”€ train_pollutant_model.py
â”‚   â”œâ”€â”€ visualize_results.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env                    # SESSION_COOKIE and driver path
â””â”€â”€ README.md
```

---

## ğŸ“Š Example Outputs

### Model Performance
![Performance](FIGURES_DIR/performance_barplot.png)

### Predicted Label Distribution
![Label Distribution](results/figures/label_distribution.png)

---

## âš™ï¸ Environment Setup

Create and activate a new environment:
```bash
conda create -n bbsr-env python=3.12
conda activate bbsr-env
```

Install required packages:
```bash
pip install -r requirements.txt
```

Create a `.env` file with:
```
SESSION_COOKIE=your_session_cookie_here
CHROMEDRIVER_PATH=/usr/local/bin/chromedriver
```

Run:
```bash
PYTHONPATH=src python scripts/train_pollutant_model.py
PYTHONPATH=src python scripts/visualize_results.py
```

---

## âš™ï¸ Quick Setup with Make

You can run common tasks using `make`:

```bash
# Install dependencies (requires conda)
make setup

# Train the model
make train

# Run predictions
make inference

# Generate performance plots and outputs
make visualize

# Do it all
make all


## ğŸ“ˆ Performance (Test Set)

| Class | Precision | Recall | F1-score |
|-------|-----------|--------|----------|
| S0    | 0.94      | 1.00   | 0.97     |
| S1    | 1.00      | 1.00   | 1.00     |
| S2    | 0.91      | 0.91   | 0.91     |
| S3    | 0.78      | 1.00   | 0.88     |
| S4    | 0.50      | 0.33   | 0.40     |

**Macro F1:** 0.83 | **Micro F1:** 0.90

---

## âœ… Next Steps

- Improve contaminant prediction with TF-IDF + logistic regression
- Use semi-supervised learning to expand labels
- Deploy in a circularity tool for interactive pollutant suggestions

---

## ğŸ¤ Credits

Developed as part of the [BBSR Challenge](https://nextcoder.de), in collaboration with Nextcoder and Circularity Tools initiative.
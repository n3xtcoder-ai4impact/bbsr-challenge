{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import seaborn as sns\n",
    "import datetime \n",
    "import chardet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal 1: Automating Pollutant Assessment \n",
    "Current Situation: \n",
    "- ​To evaluate a material's reusability, users must manually input information about \n",
    "pollutants \n",
    "- ​These pollutants (adhesives, paints, fire retardants, etc.) affect how easily materials can \n",
    "be separated and reused \n",
    "- ​The manual nature of this process introduces inconsistency and inefficiency \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Develop a system that automatically suggests strong default pollutant values based on the materials being assessed. \n",
    "This system should: \n",
    "- ​Predict likely pollutants based on material combinations \n",
    "- Provide appropriate pollutant classifications \n",
    "- Reduce manual input while improving assessment accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology and approach\n",
    "- Machine learning models to predict pollutants based on material combinations \n",
    "- Pattern recognition systems that identify common construction methods and associated \n",
    "pollutants \n",
    "- Rule-based systems derived from expert knowledge \n",
    "- ​Default value frameworks with adjustment mechanisms based on material properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guiding Questions\n",
    "\n",
    "1. How can we identify which materials are commonly used together in building components?\n",
    "2. What properties in the datasets can help us determine the type of connections used between materials?\n",
    "3. How might different connection types affect the end-of-life scenarios in the tBaustoff dataset?\n",
    "4. Can we classify connections based on their environmental impact using the lifecycle assessment data?\n",
    "5. What metrics could we use to define the \"disturbance potential\" of different connection types?\n",
    "6. How can we develop a recommendation system for material connections that optimizes for circularity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ISO-8859-1', 'confidence': 0.7295400999999999, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# detect files encoding\n",
    "with open(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/OBD_2024_I.csv\", \"rb\") as f:\n",
    "    result = chardet.detect(f.read(100000))  # Read first 100,000 bytes\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data from CSV and converting to dataframe\n",
    "oko_2024_df = pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/OBD_2024_I.csv\", delimiter=\";\", encoding = result[\"encoding\"], low_memory=False)\n",
    "oko_2023_df= pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/OBD_2023_I.csv\", delimiter=\";\", encoding = result[\"encoding\"], low_memory=False)\n",
    "oko_2020_df = pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/OBD_2020_II.csv\", delimiter=\";\", encoding = result[\"encoding\"], low_memory=False)\n",
    "tbau_df = pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/tBaustoff_with_OBD_mapping.csv\", delimiter=\";\", encoding = result[\"encoding\"], low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'confidence': 0.99, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "# detect files encoding for pollutant_combinations.csv\n",
    "with open(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/pollutant_combinations.csv\", \"rb\") as f:\n",
    "    result = chardet.detect(f.read(100000))  # Read first 100,000 bytes\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pullutant_combinations.csv\n",
    "pollutants_df = pd.read_csv(\"/Users/pablosoriano/Documents/Data Science/bbsr-challenge/csv/pollutant_combinations.csv\", delimiter=\",\", encoding = result[\"encoding\"], low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 546)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assesing if to merge the dataframes or just keep the one from 2024\n",
    "\n",
    "# Compare unique material names between datasets\n",
    "materials_2020 = set(oko_2020_df[\"Name (en)\"].dropna().unique())\n",
    "materials_2023 = set(oko_2023_df[\"Name (en)\"].dropna().unique())\n",
    "materials_2024 = set(oko_2024_df[\"Name (en)\"].dropna().unique())\n",
    "\n",
    "# Find materials in 2020 and 2023 that are not in 2024\n",
    "unique_2020 = materials_2020 - materials_2024\n",
    "unique_2023 = materials_2023 - materials_2024\n",
    "\n",
    "# Count them\n",
    "unique_2020_count = len(unique_2020)\n",
    "unique_2023_count = len(unique_2023)\n",
    "\n",
    "unique_2020_count, unique_2023_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are materials in previous datasets that are not present in the 2024 dataset:\n",
    "\n",
    "2020 has 262 materials not found in 2024.\n",
    "2023 has 546 materials not found in 2024.\n",
    "\n",
    "This means that the 2024 dataset is not a full replacement — it doesn’t include all materials from earlier versions.\n",
    "\n",
    "For maximum coverage (e.g. all materials ever documented), we should consider including previous years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the datasets\n",
    "\n",
    "# Add a source column for reference\n",
    "oko_2020_df[\"source_year\"] = 2020\n",
    "oko_2023_df[\"source_year\"] = 2023\n",
    "oko_2024_df[\"source_year\"] = 2024\n",
    "\n",
    "# Combine all datasets\n",
    "oko_combined_df = pd.concat([oko_2020_df, oko_2023_df, oko_2024_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by source year descending to keep the latest entry in case of duplicates\n",
    "combined_df_sorted = oko_combined_df.sort_values(by=\"source_year\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates keeping the latest version (based on UUID, Version, Modul)\n",
    "deduped_df = combined_df_sorted.drop_duplicates(subset=[\"UUID\", \"Version\", \"Modul\"], keep=\"first\")\n",
    "\n",
    "# Reset index and show result\n",
    "deduped_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the columns with missing values\n",
    "missing_values = deduped_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID                        0\n",
       "Version                     0\n",
       "Name (de)                2886\n",
       "Name (en)                2953\n",
       "Kategorie (original)        0\n",
       "                        ...  \n",
       "WDP (A2)                 9405\n",
       "Unnamed: 79             25665\n",
       "source_year                 0\n",
       "Stueckgewicht (kg)      25477\n",
       "Unnamed: 80             25665\n",
       "Length: 83, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL des Vorgängers        1.000000\n",
       "Unnamed: 80               1.000000\n",
       "Unnamed: 79               1.000000\n",
       "Stueckgewicht (kg)        0.992675\n",
       "Ergiebigkeit (m2)         0.987064\n",
       "Schuettdichte (kg/m3)     0.986090\n",
       "Laengengewicht (kg/m)     0.941126\n",
       "Version des Vorgängers    0.937502\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate percentage of missing values per column\n",
    "null_percentage = deduped_df.isnull().mean().sort_values(ascending=False)\n",
    "\n",
    "# Select columns with more than 90% missing values\n",
    "high_null_cols = null_percentage[null_percentage > 0.9]\n",
    "high_null_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns have extremely low data coverage and are unlikely to offer analytical value without substantial data imputation or external sourcing. Dropping them will simplify the dataset and reduce noise without significant information loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unnamed: 80 and URL des Vorgängers are completely empty → should be dropped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with >90% missing values\n",
    "columns_to_drop = [\n",
    "    \"Unnamed: 80\", \"Unnamed: 79\", \"URL des Vorgängers\",\n",
    "    \"Stueckgewicht (kg)\", \"Ergiebigkeit (m2)\", \"Schuettdichte (kg/m3)\",\n",
    "    \"Laengengewicht (kg/m)\", \"Version des Vorgängers\"\n",
    "]\n",
    "\n",
    "cleaned_df = deduped_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values of Environmental Impact Indicators (EN 15804+A1 and +2)\n",
    "\n",
    "Understanding the EN 15804 Standard and Its Impact on LCA Calculations\n",
    "The EN 15804 standard is the foundation for Environmental Product Declarations (EPDs) worldwide. In 2019, a significant update (EN 15804+A2) was released, becoming mandatory in July 2022. This update changes how environmental impacts are measured in EPDs.\n",
    "\n",
    "What Changed?\n",
    "While the environmental impact categories (like global warming and ozone depletion) are mostly the same, the units used to measure them have changed. This means that older EPDs (EN 15804+A1) cannot be directly compared or used with newer EPDs (EN 15804+A2) in LCA calculations.\n",
    "\n",
    "How does this affect Building LCA?\n",
    "Simply put, you can't mix and match old and new EPDs in your building LCA calculations.\n",
    "\n",
    "Since 15804+A1 has a big % of missing values and it's out of use, we will drop the whole columns unless they have values that are not covered in +A2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GWP     8294\n",
       " ODP     8281\n",
       " POCP    8281\n",
       " AP      8281\n",
       " ADPE    8281\n",
       " EP      8279\n",
       " ADPF    8277\n",
       " dtype: int64,\n",
       " np.int64(8294))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define A1 and A2 column groups\n",
    "a1_columns = [\"GWP\", \"ODP\", \"POCP\", \"AP\", \"EP\", \"ADPE\", \"ADPF\"]\n",
    "a2_columns = [\n",
    "    \"GWPtotal (A2)\", \"GWPbiogenic (A2)\", \"GWPfossil (A2)\", \"GWPluluc (A2)\",\n",
    "    \"ODP (A2)\", \"POCP (A2)\", \"AP (A2)\", \"EPmarine (A2)\", \"EPfreshwater (A2)\", \n",
    "    \"EPterrestrial (A2)\", \"ADPE (A2)\", \"ADPF (A2)\"\n",
    "]\n",
    "\n",
    "# Check for non-null rows in A1 indicators\n",
    "a1_non_null = (cleaned_df[a1_columns].notnull().sum()).sort_values(ascending=False)\n",
    "\n",
    "# Check for any A1 values that do not have A2 counterparts in the same row\n",
    "# Simplest heuristic: check if A1 column is filled but all A2s are null for that row\n",
    "rows_with_only_a1 = cleaned_df[a1_columns].notnull().any(axis=1) & (~cleaned_df[a2_columns].notnull().any(axis=1))\n",
    "\n",
    "# Count how many rows this applies to\n",
    "only_a1_count = rows_with_only_a1.sum()\n",
    "\n",
    "a1_non_null, only_a1_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: These A1 values are not duplicated or represented in the A2 columns — they are unique to older datasets.\n",
    "Therefore, dropping them would result in data loss for ~8,300 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "impact_standard\n",
       "A2      16260\n",
       "A1       8294\n",
       "none     1111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper column classifying the environmental impact standard\n",
    "def classify_impact_standard(row):\n",
    "    has_a1 = row[a1_columns].notnull().any()\n",
    "    has_a2 = row[a2_columns].notnull().any()\n",
    "    if has_a1 and not has_a2:\n",
    "        return \"A1\"\n",
    "    elif has_a2 and not has_a1:\n",
    "        return \"A2\"\n",
    "    elif has_a1 and has_a2:\n",
    "        return \"mixed\"\n",
    "    else:\n",
    "        return \"none\"\n",
    "\n",
    "# Apply the function\n",
    "cleaned_df[\"impact_standard\"] = cleaned_df.apply(classify_impact_standard, axis=1)\n",
    "\n",
    "# Show counts for each category\n",
    "impact_counts = cleaned_df[\"impact_standard\"].value_counts()\n",
    "\n",
    "impact_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeacademy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
